# -*- coding: utf-8 -*-
"""Project 03: Multi-output Learning

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fDF_PAVOay-mGVzRON-PNjaCHDJS1cA2
"""

!pip install -q --upgrade pip
!pip install -q torch torchvision torchaudio
!pip install -q transformers
!pip install -q datasets==2.21.0
!pip install -q evaluate
!pip install -q tqdm
from transformers import BertTokenizer, BertModel
from datasets import load_dataset
from evaluate import load
import torch
from torch.utils.data import Dataset, DataLoader
from torch.optim import AdamW
from tqdm import tqdm
device = "cuda" if torch.cuda.is_available() else "cpu"

# Some Chinese punctuations will be tokenized as [UNK], so we replace them with English ones
token_replacement = [
    ["：" , ":"],
    ["，" , ","],
    ["“" , "\""],
    ["”" , "\""],
    ["？" , "?"],
    ["……" , "..."],
    ["！" , "!"]
]

tokenizer = BertTokenizer.from_pretrained("google-bert/bert-base-uncased", cache_dir="./cache/")

class SemevalDataset(Dataset):
    def __init__(self, split="train") -> None:
        super().__init__()
        assert split in ["train", "validation", "test"]
        self.data = load_dataset(
            "sem_eval_2014_task_1", split=split, trust_remote_code=True, cache_dir="./cache/"
        ).to_list()

    def __getitem__(self, index):
        d = self.data[index]
        # Replace Chinese punctuations with English ones
        for k in ["premise", "hypothesis"]:
            for tok in token_replacement:
                d[k] = d[k].replace(tok[0], tok[1])
        return d

    def __len__(self):
        return len(self.data)

data_sample = SemevalDataset(split="train").data[:3]
print(f"Dataset example: \n{data_sample[0]} \n{data_sample[1]} \n{data_sample[2]}")

# Define the hyperparameters
# You can modify these values if needed
lr = 4e-5
epochs = 15
train_batch_size = 32
validation_batch_size = 32

# TODO1: Create batched data for DataLoader
# `collate_fn` is a function that defines how the data batch should be packed.
# This function will be called in the DataLoader to pack the data batch.

def collate_fn(batch):
    # TODO1-1: Implement the collate_fn function
    # Write your code here
    # The input parameter is a data batch (tuple), and this function packs it into tensors.
    # Use tokenizer to pack tokenize and pack the data and its corresponding labels.
    # Return the data batch and labels for each sub-task.
    premises = [item['premise'] for item in batch]
    hypotheses = [item['hypothesis'] for item in batch]

    relatedness_scores = torch.tensor(
        [item['relatedness_score'] for item in batch],
        dtype=torch.float
    )

    entailment_labels = torch.tensor(
        [item['entailment_judgment'] for item in batch],
        dtype=torch.long
    )

    encoded = tokenizer(
        premises,
        hypotheses,
        padding=True,
        truncation=True,
        max_length=128,
        return_tensors='pt'
    )
    return encoded, relatedness_scores, entailment_labels


# TODO1-2: Define your DataLoader

dl_train = DataLoader(
    SemevalDataset(split="train"),
    batch_size=train_batch_size,
    shuffle=True,
    collate_fn=collate_fn
)

dl_validation = DataLoader(
    SemevalDataset(split="validation"),
    batch_size=validation_batch_size,
    shuffle=False,
    collate_fn=collate_fn
)

dl_test = DataLoader(
    SemevalDataset(split="test"),
    batch_size=validation_batch_size,
    shuffle=False,
    collate_fn=collate_fn
)

# TODO2: Construct your model
class MultiLabelModel(torch.nn.Module):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)

        # 1. Load pre-trained BERT model (bert-base-uncased)
        self.bert = BertModel.from_pretrained(
            "google-bert/bert-base-uncased",
            cache_dir="./cache/")
        # 2. Dropout layer for regularization
        self.dropout = torch.nn.Dropout(0.2)
        # 3. Linear layer for regression task (relatedness_score prediction)
        self.regressor = torch.nn.Linear(self.bert.config.hidden_size, 1)
        # 4. Linear layer for classification task (entailment_judgement prediction)
        self.classifier = torch.nn.Linear(self.bert.config.hidden_size, 3)

    def forward(self, **kwargs):
        outputs = self.bert(
            input_ids=kwargs['input_ids'],
            attention_mask=kwargs['attention_mask'],
            token_type_ids=kwargs['token_type_ids'])
        pooled_output = outputs.pooler_output
        pooled_output = self.dropout(pooled_output)
        regression_output = self.regressor(pooled_output).squeeze(-1)
        classification_output = self.classifier(pooled_output)
        return regression_output, classification_output

# TODO3: Define your optimizer and loss function

model = MultiLabelModel().to(device)

# TODO3-1: Define your Optimizer
optimizer = AdamW(model.parameters(), lr=lr)

# TODO3-2: Define your loss functions (you should have two)
loss_fn_regression = torch.nn.MSELoss()
loss_fn_classification = torch.nn.CrossEntropyLoss()

# scoring functions
psr = load("pearsonr")
acc = load("accuracy")

import os
os.makedirs('./saved_models/', exist_ok=True)
model = model.to(device)

best_score = 0.0

for ep in range(epochs):
    # Training
    pbar = tqdm(dl_train)
    pbar.set_description(f"Training epoch [{ep+1}/{epochs}]")
    model.train()

    for batch in pbar:
        encoded, relatedness_scores, entailment_labels = batch

        encoded = {k: v.to(device, non_blocking=True) for k, v in encoded.items()}
        relatedness_scores = relatedness_scores.to(device, non_blocking=True)
        entailment_labels = entailment_labels.to(device, non_blocking=True)

        optimizer.zero_grad(set_to_none=True)

        regression_output, classification_output = model(**encoded)

        loss_reg = loss_fn_regression(regression_output, relatedness_scores)
        loss_cls = loss_fn_classification(classification_output, entailment_labels)
        total_loss = loss_reg + loss_cls

        total_loss.backward()

        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)

        optimizer.step()

        pbar.set_postfix({
            'loss': total_loss.item(),
            'loss_reg': loss_reg.item(),
            'loss_cls': loss_cls.item()
        })

    # Validation
    pbar = tqdm(dl_validation)
    pbar.set_description(f"Validation epoch [{ep+1}/{epochs}]")
    model.eval()

    all_regression_preds = []
    all_regression_labels = []
    all_classification_preds = []
    all_classification_labels = []

    with torch.no_grad():
        for batch in pbar:
            encoded, relatedness_scores, entailment_labels = batch

            encoded = {k: v.to(device, non_blocking=True) for k, v in encoded.items()}
            relatedness_scores = relatedness_scores.to(device, non_blocking=True)
            entailment_labels = entailment_labels.to(device, non_blocking=True)

            regression_output, classification_output = model(**encoded)
            classification_preds = torch.argmax(classification_output, dim=-1)

            all_regression_preds.extend(regression_output.detach().cpu().tolist())
            all_regression_labels.extend(relatedness_scores.detach().cpu().tolist())
            all_classification_preds.extend(classification_preds.detach().cpu().tolist())
            all_classification_labels.extend(entailment_labels.detach().cpu().tolist())

    pearson_corr = psr.compute(
        predictions=all_regression_preds,
        references=all_regression_labels
    )['pearsonr']

    accuracy = acc.compute(
        predictions=all_classification_preds,
        references=all_classification_labels
    )['accuracy']

    print(f"\nEpoch {ep+1}/{epochs} Evaluation Results:")
    print(f"  Pearson Correlation (Relatedness): {pearson_corr:.4f}")
    print(f"  Accuracy (Entailment): {accuracy:.4f}")
    print(f"  Combined Score: {pearson_corr + accuracy:.4f}")

    if pearson_corr + accuracy > best_score:
        best_score = pearson_corr + accuracy
        torch.save(model.state_dict(), f'./saved_models/best_model.ckpt')

# Load the model
model = MultiLabelModel().to(device)
model.load_state_dict(torch.load(f"./saved_models/best_model.ckpt", weights_only=True))

# Test Loop
pbar = tqdm(dl_test, desc="Test")
model.eval()

all_regression_preds = []
all_regression_labels = []
all_classification_preds = []
all_classification_labels = []

with torch.no_grad():
    for batch in pbar:
        encoded, relatedness_scores, entailment_labels = batch

        encoded = {k: v.to(device) for k, v in encoded.items()}
        relatedness_scores = relatedness_scores.to(device)
        entailment_labels = entailment_labels.to(device)

        regression_output, classification_output = model(**encoded)
        classification_preds = torch.argmax(classification_output, dim=-1)

        all_regression_preds.extend(regression_output.cpu().tolist())
        all_regression_labels.extend(relatedness_scores.cpu().tolist())
        all_classification_preds.extend(classification_preds.cpu().tolist())
        all_classification_labels.extend(entailment_labels.cpu().tolist())

test_pearson_corr = psr.compute(
    predictions=all_regression_preds,
    references=all_regression_labels
)['pearsonr']

test_accuracy = acc.compute(
    predictions=all_classification_preds,
    references=all_classification_labels
)['accuracy']


print("")
print(f"Test Set Size: {len(all_regression_labels)} samples")
print("="*70)
print(f"\nRegression Task (Relatedness Score):")
print(f"  Pearson Correlation Coefficient: {test_pearson_corr:.4f}")
print(f"\nClassification Task (Entailment Judgement):")
print(f"  Accuracy: {test_accuracy:.4f}")
print(f"\nCombined Score: {test_pearson_corr + test_accuracy:.4f}")
print("="*70)
print(f"Model Performance: Pearson {test_pearson_corr:.4f}, Accuracy {test_accuracy:.4f}, Combined {test_pearson_corr + test_accuracy:.4f}")
print("="*70)
